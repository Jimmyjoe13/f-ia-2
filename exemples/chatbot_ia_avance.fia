# ===========================
# CHATBOT F-IA AVEC IA INTÃ‰GRÃ‰E
# Chatbot conversationnel utilisant OpenAI GPT et DeepSeek
# ===========================

# === INITIALISATION ET VÃ‰RIFICATION DU SYSTÃˆME ===
imprimer("ğŸ¤– === CHATBOT F-IA AVEC IA INTÃ‰GRÃ‰E ===")
imprimer("Chargement du systÃ¨me IA...")

# VÃ©rifier la configuration des plateformes IA (clÃ©s API)
soit config_ia = verifier_config_ia()
imprimer("ğŸ“Š Ã‰tat de la configuration IA:")
imprimer("  OpenAI:", config_ia["openai"])   # Affiche true/false selon la config
imprimer("  DeepSeek:", config_ia["deepseek"])

# RÃ©cupÃ©rer les plateformes IA disponibles (configurÃ©es)
soit plateformes = lister_plateformes_ia()
si (longueur(plateformes) == 0) {
    # Aucune plateforme configurÃ©e - arrÃªter avec message d'aide
    imprimer("âŒ Aucune plateforme IA configurÃ©e!")
    imprimer("ğŸ’¡ Configurez vos clÃ©s API dans le fichier .env")
    imprimer("   OPENAI_API_KEY=votre_cle_openai")
    imprimer("   DEEPSEEK_API_KEY=votre_cle_deepseek")
    arreter()
}

imprimer("âœ… Plateformes IA disponibles:", plateformes)

# === CONFIGURATION INITIALE DU BOT ===
# SÃ©lectionner la premiÃ¨re plateforme disponible par dÃ©faut
soit plateforme_defaut = plateformes[0]
soit modele_defaut = "gpt-4.1-nano"  # ModÃ¨le OpenAI par dÃ©faut

# Adapter le modÃ¨le selon la plateforme sÃ©lectionnÃ©e
si (plateforme_defaut == "deepseek") {
    modele_defaut = "deepseek-chat"  # ModÃ¨le DeepSeek pour conversation
}

imprimer("ğŸ¯ Plateforme active:", plateforme_defaut)
imprimer("ğŸ§  ModÃ¨le:", modele_defaut)

# Variables de configuration du chatbot
soit nom_bot = "F-IA Assistant Pro"
soit contexte_bot = "Tu es un assistant intelligent crÃ©Ã© avec le langage F-IA. Tu es serviable, crÃ©atif et tu parles franÃ§ais naturellement."
soit compteur_messages = 0  # Compteur des messages Ã©changÃ©s
soit historique = []         # Historique des 10 derniers Ã©changes

# === FONCTIONS UTILITAIRES ===

# Fonction pour gÃ©rer l'historique des conversations
fonction ajouter_historique(message, reponse) {
    # Ajouter l'Ã©change Ã  l'historique
    ajouter(historique, {"message": message, "reponse": reponse})
    # Limiter Ã  10 Ã©changes maximum
    si (longueur(historique) > 10) {
        retirer(historique, 0)  # Supprimer le plus ancien
    }
}

# Fonction d'affichage de l'aide utilisateur
fonction afficher_aide() {
    imprimer("ğŸ“– === AIDE CHATBOT F-IA PRO ===")
    imprimer("Commandes spÃ©ciales:")
    imprimer("  /aide       - Afficher cette aide")
    imprimer("  /stats      - Statistiques du bot")
    imprimer("  /historique - Voir les derniers Ã©changes")
    imprimer("  /modele     - Changer de modÃ¨le IA")
    imprimer("  /plateforme - Changer de plateforme IA")
    imprimer("  /reset      - RÃ©initialiser l'historique")
    imprimer("  quitter     - Fermer le chatbot")
    imprimer("")
    imprimer("ğŸ’¬ Parlez-moi naturellement pour une conversation IA!")
}

# Fonction d'affichage des statistiques du bot
fonction afficher_stats() {
    imprimer("ğŸ“Š === STATISTIQUES ===")
    imprimer("Bot:", nom_bot)
    imprimer("Plateforme:", plateforme_defaut)
    imprimer("ModÃ¨le:", modele_defaut)
    imprimer("Messages Ã©changÃ©s:", compteur_messages)
    imprimer("Historique:", longueur(historique), "Ã©changes")
}

# Fonction d'affichage de l'historique des conversations
fonction afficher_historique() {
    imprimer("ğŸ“œ === HISTORIQUE ===")
    si (longueur(historique) == 0) {
        imprimer("Aucun historique disponible.")
    } sinon {
        # Parcourir et afficher tous les Ã©changes
        soit i = 0
        tant_que (i < longueur(historique)) {
            soit echange = historique[i]
            imprimer("ğŸ‘¤ Vous:", echange["message"])
            imprimer("ğŸ¤– Bot:", echange["reponse"])
            imprimer("---")
            i = i + 1
        }
    }
}

# Fonction pour changer de modÃ¨le IA
fonction changer_modele() {
    imprimer("ğŸ§  ModÃ¨les disponibles pour", plateforme_defaut, ":")
    soit modeles = lister_modeles_ia(plateforme_defaut)
    
    # Afficher la liste numÃ©rotÃ©e des modÃ¨les
    soit i = 0
    tant_que (i < longueur(modeles)) {
        imprimer("  ", i + 1, ".", modeles[i])
        i = i + 1
    }
    
    imprimer("Tapez le numÃ©ro du modÃ¨le ou EntrÃ©e pour annuler:")
    soit choix = lire()
    
    # Traiter le choix utilisateur (gestion manuelle car pas de conversion entier())
    si (choix != "") {
        si (choix == "1") {
            modele_defaut = modeles[0]
            imprimer("âœ… ModÃ¨le changÃ© pour:", modele_defaut)
        } sinon si (choix == "2") {
            si (longueur(modeles) > 1) {
                modele_defaut = modeles[1]
                imprimer("âœ… ModÃ¨le changÃ© pour:", modele_defaut)
            } sinon {
                imprimer("âŒ NumÃ©ro invalide")
            }
        } sinon si (choix == "3") {
            si (longueur(modeles) > 2) {
                modele_defaut = modeles[2]
                imprimer("âœ… ModÃ¨le changÃ© pour:", modele_defaut)
            } sinon {
                imprimer("âŒ NumÃ©ro invalide")
            }
        } sinon {
            imprimer("âŒ NumÃ©ro invalide")  # Choix non supportÃ©
        }
    }
}

# Fonction pour changer de plateforme IA
fonction changer_plateforme() {
    imprimer("ğŸŒ Plateformes disponibles:")
    
    # Afficher la liste des plateformes disponibles
    soit i = 0
    tant_que (i < longueur(plateformes)) {
        imprimer("  ", i + 1, ".", plateformes[i])
        i = i + 1
    }
    
    imprimer("Tapez le numÃ©ro de la plateforme ou EntrÃ©e pour annuler:")
    soit choix = lire()
    
    # Traiter le choix de plateforme
    si (choix != "") {
        si (choix == "1") {
            plateforme_defaut = plateformes[0]
            # Adapter automatiquement le modÃ¨le par dÃ©faut
            si (plateforme_defaut == "openai") {
                modele_defaut = "gpt-4.1-nano"
            } sinon si (plateforme_defaut == "deepseek") {
                modele_defaut = "deepseek-chat"
            }
            imprimer("âœ… Plateforme changÃ©e pour:", plateforme_defaut)
            imprimer("ğŸ§  ModÃ¨le adaptÃ©:", modele_defaut)
        } sinon si (choix == "2") {
            si (longueur(plateformes) > 1) {
                plateforme_defaut = plateformes[1]
                # Adapter le modÃ¨le (BUG: devrait Ãªtre gpt-4.1-nano pas gpt-3.5)
                si (plateforme_defaut == "openai") {
                    modele_defaut = "gpt-4.1-nano"  # TODO: Corriger en gpt-4.1-nano
                } sinon si (plateforme_defaut == "deepseek") {
                    modele_defaut = "deepseek-chat"
                }
                imprimer("âœ… Plateforme changÃ©e pour:", plateforme_defaut)
                imprimer("ğŸ§  ModÃ¨le adaptÃ©:", modele_defaut)
            } sinon {
                imprimer("âŒ NumÃ©ro invalide")
            }
        } sinon {
            imprimer("âŒ NumÃ©ro invalide")  # Choix non supportÃ©
        }
    }
}

# === DÃ‰MARRAGE DU CHATBOT ===
imprimer("")
imprimer("ğŸ‰ Bienvenue dans", nom_bot, "!")
imprimer("PropulsÃ© par", plateforme_defaut, "avec le modÃ¨le", modele_defaut)
afficher_aide()  # Afficher l'aide au dÃ©marrage

# === BOUCLE PRINCIPALE DU CHATBOT ===
tant_que (vrai) {  # Boucle infinie jusqu'Ã  "quitter"
    imprimer("")
    imprimer("ğŸ‘¤ Vous:")
    soit message_utilisateur = lire()  # Lire l'entrÃ©e utilisateur
    
    # === TRAITEMENT DES COMMANDES SPÃ‰CIALES ===
    si (message_utilisateur == "quitter") {
        # Commande de sortie
        imprimer("ğŸ‘‹ Merci d'avoir utilisÃ©", nom_bot, "!")
        imprimer("ğŸ’» DÃ©veloppÃ© avec le langage F-IA")
        arreter()
    } sinon si (message_utilisateur == "/aide") {
        afficher_aide()  # Afficher l'aide
    } sinon si (message_utilisateur == "/stats") {
        afficher_stats()  # Afficher les statistiques
    } sinon si (message_utilisateur == "/historique") {
        afficher_historique()  # Afficher l'historique
    } sinon si (message_utilisateur == "/modele") {
        changer_modele()  # Interface de changement de modÃ¨le
    } sinon si (message_utilisateur == "/plateforme") {
        changer_plateforme()  # Interface de changement de plateforme
    } sinon si (message_utilisateur == "/reset") {
        # RÃ©initialiser l'historique et les compteurs
        historique = []
        compteur_messages = 0
        imprimer("ğŸ”„ Historique rÃ©initialisÃ©!")
    } sinon si (message_utilisateur == "") {
        # Message vide - demander une entrÃ©e
        imprimer("ğŸ’­ Tapez quelque chose ou /aide pour l'aide")
    } sinon {
        # === TRAITEMENT DES MESSAGES NORMAUX AVEC IA ===
        imprimer("ğŸ¤–", nom_bot, "rÃ©flÃ©chit...")
        
        # Appeler l'IA pour gÃ©nÃ©rer une rÃ©ponse contextuelle
        soit reponse_ia = generer_reponse_bot(
            plateforme_defaut,    # Plateforme IA active
            modele_defaut,        # ModÃ¨le IA actif
            message_utilisateur,  # Message de l'utilisateur
            contexte_bot         # Contexte/personnalitÃ© du bot
        )
        
        # Afficher la rÃ©ponse de l'IA
        imprimer("ğŸ¤–", nom_bot, ":", reponse_ia)
        
        # Sauvegarder l'Ã©change dans l'historique
        ajouter_historique(message_utilisateur, reponse_ia)
        compteur_messages = compteur_messages + 1  # IncrÃ©menter le compteur
    }
}

# === FIN DU PROGRAMME ===
# Le programme se termine quand l'utilisateur tape "quitter"
# ou si une erreur critique survient (arreter() appelÃ©)
